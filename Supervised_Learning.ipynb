{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpsy3mpQbSZOXd0KqpGfn9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeeraAdhi/NM-projects/blob/main/Supervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q scikit-learn gradio pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gradio as gr\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a logistic regression model\n",
        "model = LogisticRegression(max_iter=200, solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate model accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy on test set: {accuracy:.4f}\")\n",
        "\n",
        "# Prediction function\n",
        "def predict_iris_species(sepal_length, sepal_width, petal_length, petal_width):\n",
        "    input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "    prediction_index = model.predict(input_data)[0]\n",
        "    probabilities = model.predict_proba(input_data)[0]\n",
        "    predicted_species = target_names[prediction_index]\n",
        "    confidence_scores = {target_names[i]: float(probabilities[i]) for i in range(len(target_names))}\n",
        "    return predicted_species, confidence_scores\n",
        "\n",
        "# Gradio Interface\n",
        "inputs = [\n",
        "    gr.Slider(4.0, 8.0, value=5.4, label=\"Sepal Length (cm)\"),\n",
        "    gr.Slider(2.0, 4.5, value=3.4, label=\"Sepal Width (cm)\"),\n",
        "    gr.Slider(1.0, 7.0, value=1.3, label=\"Petal Length (cm)\"),\n",
        "    gr.Slider(0.1, 2.5, value=0.2, label=\"Petal Width (cm)\")\n",
        "]\n",
        "\n",
        "outputs = [\n",
        "    gr.Textbox(label=\"Predicted Iris Species\"),\n",
        "    gr.JSON(label=\"Confidence Scores\")  # gr.Label may throw errors in some versions\n",
        "]\n",
        "\n",
        "# Launch app\n",
        "gr.Interface(\n",
        "    fn=predict_iris_species,\n",
        "    inputs=inputs,\n",
        "    outputs=outputs,\n",
        "    title=\"🌸 Iris Flower Species Predictor\",\n",
        "    description=\"Adjust the sliders to input flower measurements and predict the Iris species.\",\n",
        "    examples=[\n",
        "        [5.1, 3.5, 1.4, 0.2],\n",
        "        [6.2, 3.4, 5.4, 2.3],\n",
        "        [5.8, 2.7, 4.1, 1.0]\n",
        "    ],\n",
        "    allow_flagging=\"never\"\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "EOziv-EMWRtI",
        "outputId": "bbde4ea4-34cc-47be-d89a-b2389efe5fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hModel Accuracy on test set: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:416: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a02570ff0d6f175809.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a02570ff0d6f175809.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}