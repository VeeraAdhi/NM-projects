{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1w7L4-qFzL9kwIIl8gu9CvEr6r3BCIIq7",
      "authorship_tag": "ABX9TyOomeMU1bJ2+F3Gf0EVTAB9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VeeraAdhi/NM-projects/blob/main/Linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample dataset (RAM in GB, Storage in GB) and Mobile Price ($100s)\n",
        "data = np.array([\n",
        "    [2, 16, 50], [3, 32, 80], [4, 64, 120], [6, 128, 180],\n",
        "    [8, 256, 250], [12, 512, 350], [16, 1024, 450]\n",
        "])\n",
        "\n",
        "# Splitting features and target\n",
        "X = data[:, :2]  # RAM & Storage\n",
        "y = data[:, 2]   # Price\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "def predict_price(ram, storage):\n",
        "    price = model.predict([[ram, storage]])[0]\n",
        "    return f\"Predicted Price: ╣{price * 100:.2f}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_price,\n",
        "    inputs=[gr.Slider(2, 16, step=1, label=\"RAM (GB)\"), gr.Slider(16, 1024, step=16, label=\"Storage (GB)\")],\n",
        "    outputs=\"text\",\n",
        "    title=\"Mobile Phone Price Predictor\",\n",
        "    description=\"Enter RAM and Storage to predict mobile price.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "7a9rSbhROEM8",
        "outputId": "47b14746-8237-4cd8-c05f-08852191ed72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://05fb5a111deeab2417.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://05fb5a111deeab2417.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", header=None)\n",
        "\n",
        "data.columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "def predict_disease(preg, glucose, bp, skin, insulin, bmi, dpf, age):\n",
        "    user_data = np.array([[preg, glucose, bp, skin, insulin, bmi, dpf, age]])\n",
        "    user_data = scaler.transform(user_data)\n",
        "    prediction = model.predict(user_data)[0]\n",
        "\n",
        "    if prediction == 1:\n",
        "        level = \"High Risk\"\n",
        "        recommendation = \"1. Maintain a balanced diet.\\n2. Exercise regularly.\"\n",
        "        result = \"Diabetic\"\n",
        "    else:\n",
        "        level = \"Low Risk\"\n",
        "        recommendation = \"1. Continue a healthy lifestyle.\\n2. Regularly monitor blood sugar levels.\"\n",
        "        result = \"Not Diabetic\"\n",
        "\n",
        "    return f\"Result: {result}\\nRisk Level: {level}\\nRecommendations:\\n{recommendation}\"\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=predict_disease,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Pregnancies (count, 0-17)\"),\n",
        "        gr.Number(label=\"Glucose Level (mg/dL, 50-200)\"),\n",
        "        gr.Number(label=\"Blood Pressure (mmHg, 40-130)\"),\n",
        "        gr.Number(label=\"Skin Thickness (mm, 0-99)\"),\n",
        "        gr.Number(label=\"Insulin Level (IU/mL, 0-850)\"),\n",
        "        gr.Number(label=\"BMI (kg/m², 10-60)\"),\n",
        "        gr.Number(label=\"Diabetes Pedigree Function (score, 0.08-2.50)\"),\n",
        "        gr.Number(label=\"Age (years, 21-90)\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Diabetes Prediction\",\n",
        "    description=\"Enter health parameters to check if the person is diabetic.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "yLkw_6DEU3Qz",
        "outputId": "a63be3a7-4591-43d4-9d8a-7a7526baa334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3eb104a85c3444421c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3eb104a85c3444421c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}